{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#百度语音识别\n",
    "\n",
    "from aip import AipSpeech\n",
    "\n",
    " \n",
    "\n",
    "\"\"\" 你的 APPID AK SK \"\"\"\n",
    "\n",
    "APP_ID = ''\n",
    "\n",
    "API_KEY = ''\n",
    "\n",
    "SECRET_KEY = ''\n",
    "\n",
    " \n",
    "\n",
    "client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)\n",
    "\n",
    " \n",
    "\n",
    "# 读取文件\n",
    "\n",
    "def get_file_content(filePath):\n",
    "\n",
    "    with open(filePath, 'rb') as fp:\n",
    "\n",
    "        return fp.read()\n",
    "\n",
    " \n",
    "\n",
    "# 识别本地文件\n",
    "\n",
    "rtn = client.asr(get_file_content('16k-23850.amr'), 'amr', 16000, {\n",
    "\n",
    "    'dev_pid': 1536,\n",
    "\n",
    "})\n",
    "\n",
    " \n",
    "\n",
    "print(rtn['result'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#阿里语音识别\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import ali_speech\n",
    "from ali_speech.callbacks import SpeechTranscriberCallback\n",
    "from ali_speech.constant import ASRFormat\n",
    "from ali_speech.constant import ASRSampleRate\n",
    "class MyCallback(SpeechTranscriberCallback):\n",
    "    \"\"\"\n",
    "    构造函数的参数没有要求，可根据需要设置添加\n",
    "    示例中的name参数可作为待识别的音频文件名，用于在多线程中进行区分\n",
    "    \"\"\"\n",
    "    def __init__(self, name='default'):\n",
    "        self._name = name\n",
    "    def on_started(self, message):\n",
    "        print('MyCallback.OnRecognitionStarted: %s' % message)\n",
    "    def on_result_changed(self, message):\n",
    "        print('MyCallback.OnRecognitionResultChanged: file: %s, task_id: %s, result: %s' % (\n",
    "            self._name, message['header']['task_id'], message['payload']['result']))\n",
    "    def on_sentence_begin(self, message):\n",
    "        print('MyCallback.on_sentence_begin: file: %s, task_id: %s, sentence_id: %s, time: %s' % (\n",
    "            self._name, message['header']['task_id'], message['payload']['index'], message['payload']['time']))\n",
    "    def on_sentence_end(self, message):\n",
    "        print('MyCallback.on_sentence_end: file: %s, task_id: %s, sentence_id: %s, time: %s, result: %s' % (\n",
    "            self._name,\n",
    "            message['header']['task_id'], message['payload']['index'],\n",
    "            message['payload']['time'], message['payload']['result']))\n",
    "    def on_completed(self, message):\n",
    "        print('MyCallback.OnRecognitionCompleted: %s' % message)\n",
    "    def on_task_failed(self, message):\n",
    "        print('MyCallback.OnRecognitionTaskFailed-task_id:%s, status_text:%s' % (\n",
    "            message['header']['task_id'], message['header']['status_text']))\n",
    "    def on_channel_closed(self):\n",
    "        print('MyCallback.OnRecognitionChannelClosed')\n",
    "def process(client, appkey, token):\n",
    "    audio_name = 'nls-sample-16k.wav'\n",
    "    callback = MyCallback(audio_name)\n",
    "    transcriber = client.create_transcriber(callback)\n",
    "    transcriber.set_appkey(appkey)\n",
    "    transcriber.set_token(token)\n",
    "    transcriber.set_format(ASRFormat.PCM)\n",
    "    transcriber.set_sample_rate(ASRSampleRate.SAMPLE_RATE_16K)\n",
    "    transcriber.set_enable_intermediate_result(False)\n",
    "    transcriber.set_enable_punctuation_prediction(True)\n",
    "    transcriber.set_enable_inverse_text_normalization(True)\n",
    "    try:\n",
    "        ret = transcriber.start()\n",
    "        if ret < 0:\n",
    "            return ret\n",
    "        print('sending audio...')\n",
    "        with open(audio_name, 'rb') as f:\n",
    "            audio = f.read(3200)\n",
    "            while audio:\n",
    "                ret = transcriber.send(audio)\n",
    "                if ret < 0:\n",
    "                    break\n",
    "                time.sleep(0.1)\n",
    "                audio = f.read(3200)\n",
    "        transcriber.stop()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        transcriber.close()\n",
    "def process_multithread(client, appkey, token, number):\n",
    "    thread_list = []\n",
    "    for i in range(0, number):\n",
    "        thread = threading.Thread(target=process, args=(client, appkey, token))\n",
    "        thread_list.append(thread)\n",
    "        thread.start()\n",
    "    for thread in thread_list:\n",
    "        thread.join()\n",
    "if __name__ == \"__main__\":\n",
    "    client = ali_speech.NlsClient()\n",
    "    # 设置输出日志信息的级别：DEBUG、INFO、WARNING、ERROR\n",
    "    client.set_log_level('INFO')\n",
    "    appkey = '您的appkey'\n",
    "    token = '您的Token'\n",
    "    process(client, appkey, token)\n",
    "    # 多线程示例\n",
    "    # process_multithread(client, appkey, token, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#百度人脸识别api\n",
    "import urllib3,base64\n",
    "from urllib.parse import urlencode\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "t1=time.time()\n",
    "access_token='your token'\n",
    "http=urllib3.PoolManager()\n",
    "url='https://aip.baidubce.com/rest/2.0/face/v2/detect?access_token='+access_token\n",
    "#2张图片\n",
    "filepath='D:/作业！！！！！！！！！！！！！！！！！/大三/上/API/期末/r.jpg'\n",
    "f1 = open(filepath,'rb')\n",
    "frame=cv2.imread(filepath)\n",
    "#参数images：图像base64编码 分别base64编码后的2张图片数据，需urlencode，半角逗号分隔，单次请求最大不超过20M\n",
    "img1 = base64.b64encode(f1.read())\n",
    "\n",
    "#这一步和官方示例代码不一样。具体为什么就不知道了。里面有json bytes str 类型关系\n",
    "#这里直接拼接提示byte相关。然后就直接转str拼接了\n",
    "params = {\"images\":str(img1,'utf-8'),\"max_face_num\":10}\n",
    "#对base64数据进行urlencode处理\n",
    "params=urlencode(params)\n",
    "request=http.request('POST',\n",
    "                      url,\n",
    "                      body=params,\n",
    "                      headers={'Content-Type':'application/x-www-form-urlencoded'})\n",
    "#对返回的byte字节进行处理。Python3输出位串，而不是可读的字符串，需要进行转换\n",
    "\n",
    "print(json.loads(request.data))  # request.data 返回有关的信息但是是json类型  然后使用json.loads 进行转换转成python支持的dict\n",
    "result = json.loads(request.data)['result']  #分析返回的数据 找到有用的信息拿出来 我们这里是要拿出来人脸坐标\n",
    "print(result)\n",
    "face_num=json.loads(request.data)['result_num']  #获取到图片中人脸的个数\n",
    "\n",
    "for i in range(face_num):  #使用遍历把所有的人脸都标出框\n",
    "\n",
    "    location=result[i]['location']  #获取到人脸的坐标\n",
    "    print(location)   #输出人脸坐标 left location是左上角坐标  width 宽度height高度\n",
    "    cv2.rectangle(frame, (location['left'], location['top']), (location['width']+location['left'], location['height']+location['top']), (0, 0, 255), 2) #opencv的标框函数\n",
    "\n",
    "cv2.imshow('tuxiang',frame)\n",
    "cv2.waitKey(1)  #刷新界面 不然只会呈现灰色\n",
    "print('运行时间是{}'.format(time.time()-t1))\n",
    "time.sleep(5)  #暂停五秒  展示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
